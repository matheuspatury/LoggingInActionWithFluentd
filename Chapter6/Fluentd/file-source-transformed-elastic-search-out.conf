# This configuration for Chapter 6 to illustrate the user of filtering and Elastic Search
<system>
    Log_Level info
</system>

#### begin - tail basic file
<source>
  @type tail
  @id tail
  path ./Chapter6/basic-file.txt
  read_lines_limit 5
  tag basicFile
  pos_file ./Chapter6/basic-file-read.pos_file
  read_from_head true
  <parse>
    @type json
  </parse>
</source>

<filter *>
  @type stdout
    <inject>
    post source
  </inject>
</filter>

<filter *>
  @type grep
  <regexp>
    key msg
    pattern /computer/
  </regexp>
</filter>

<filter *>
  @type record_transformer
  enable_ruby true
  <record>
    computer ${hostname}
    from  ${record.dig("name", "firstname")}
    msg processed ${record["msg"]}
  </record>
    remove_keys $.name.surname
</filter>

<filter *>
  @type stdout
  <inject>
     worker_id_key  
  </inject>
</filter>

<match *>
  @type elasticsearch
  host localhost
  port 9200
  index_name fluentd-book-enriched
  scheme http
  logstash_format false
  reload_on_failure true
  include_tag_key true
  tag_key key
  <buffer>
    flush_interval 5s
  </buffer>
</match>
